





import pandas as pd 
data = {
    'size_in_sqft_x' : [1000, 1200, 1500, 1800, 2000],
    'price_y' : [200, 240, 300, 360, 400]
}
df = pd.DataFrame(data)
df





from matplotlib import pyplot as plt 
plt.figure(figsize=(8, 6))
plt.scatter(df['size_in_sqft_x'], df['price_y'])
plt.plot(df['size_in_sqft_x'], df['price_y'], color = 'red', linestyle = 'dashed')
for i, row in df.iterrows():
    plt.annotate(f"({row['size_in_sqft_x']}, {row['price_y']})", (row['size_in_sqft_x'], row['price_y']))
plt.xlabel('size in sqft')
plt.ylabel('price')
plt.grid(True)
plt.show()








import numpy as np 
import pandas as pd 
from matplotlib.pyplot import subplots


import statsmodels.api as sm 


from statsmodels.stats.outliers_influence \
import variance_inflation_factor as VIF
from statsmodels.stats.anova import anova_lm


from ISLP import load_data
from ISLP.models import (ModelSpec as MS, summarize, poly)


A = np.array([3, 2, 4])
# dir(A)





boston = load_data('Boston')
boston.head()


boston.columns


x = pd.DataFrame({
    'intercept' : np.ones(boston.shape[0]),
    'lstat' : boston['lstat']
})
x.head()


'''
sm.OLS(y, X) creates an Ordinary Least Squares (OLS) regression
model where y is the dependent variable (the outcome we are trying to predict), 
and x is the matrix of independent variables (the predictors).
'''
y = boston['medv']
model = sm.OLS(y, x) 
results = model.fit() 


# print(results.summary())


design = MS(['lstat'])
design = design.fit(boston)
x = design.transform(boston)
x.head()


design = MS(['lstat'])
x = design.fit_transform(boston)
x.head()


results.params


new_df = pd.DataFrame({
    'lstat' : [5, 10, 15]
})
new_x = design.transform(new_df)
print(new_x)


new_predictions = results.get_prediction(new_x)
new_predictions.predicted_mean


new_predictions.conf_int(alpha=0.05)


# def abline(ax, b, m):
#     xlim = ax.get_xlim()
#     ylim = [m * xlim[0] + b, m * xlim[1] + b]
#     ax.plot(xlim, ylim)


def abline(ax, b, m, *args , **kwargs):
    xlim = ax.get_xlim()
    ylim = [m * xlim[0] + b, m * xlim[1] + b]
    ax.plot(xlim , ylim , *args , **kwargs)


ax = boston.plot.scatter('lstat', 'medv')
abline(ax, results.params.iloc[0], results.params.iloc[1], 'r--', linewidth=3)


infl = results.get_influence()
ax = subplots(figsize=(8,8))[1]
ax.scatter(np.arange(x.shape[0]), infl.hat_matrix_diag)
ax.set_xlabel('Index')
ax.set_ylabel('Leverage')
np.argmax(infl.hat_matrix_diag)





boston.columns


X = MS(['lstat', 'age']).fit_transform(boston)
model1 = sm.OLS(y, X)
results1 = model1.fit()
summarize(results1)


terms = boston.columns.drop('medv')
terms


X = MS(terms).fit_transform(boston)
model = sm.OLS(y, X)
results = model.fit()
summarize(results)


vals = [VIF(X, i)
        for i in range(1, X.shape[1])]
vif = pd.DataFrame({'vif':vals}, index=X.columns [1:])
vif


vals = []
for i in range(1, X.values.shape[1]):
    vals.append(VIF(X.values, i))


X = MS(['lstat',
        'age',
        ('lstat', 'age')]).fit_transform(boston)
model2 = sm.OLS(y, X)
summarize(model2.fit())





x = MS([poly('lstat', degree = 2), 'age']).fit_transform(boston)
model3 = sm.OLS(y, x)
result3 = model3.fit()
summarize(result3)


anova_lm(results1, result3)


ax = subplots(figsize=(8,8))[1]
ax.scatter(result3.fittedvalues , result3.resid)
ax.set_xlabel('Fitted value')
ax.set_ylabel('Residual')
ax.axhline(0, c='k', ls='--')





carseats = load_data('Carseats')
carseats.columns


allvars = list(carseats.columns.drop('Sales'))
y = carseats['Sales']
final = allvars + [('Income', 'Advertising'), ('Price', 'Age')]

x = MS(final).fit_transform(carseats)
model = sm.OLS(y, x) 
summarize(model.fit())








import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn import linear_model


data = {
    'area' : [2600, 3000, 3200, 3600, 4000], 
    'price' : [550000, 565000, 610000, 680000, 725000]
}
df = pd.DataFrame(data) 
df





%matplotlib inline
plt.xlabel('area(in sqft)')
plt.ylabel('price')
plt.scatter(df['area'], df['price'], color = 'red', marker='+')





reg = linear_model.LinearRegression()


reg.fit(df[['area']], df['price'])


df_pred = pd.DataFrame({'area' : [3300]})
reg.predict(df_pred)


df_pred = pd.DataFrame({'area' : [5000]})
reg.predict(df_pred)


reg.coef_


reg.intercept_


%matplotlib inline
plt.xlabel('area', fontsize = 15)
plt.ylabel('price', fontsize = 15) 
plt.scatter(df['area'], df['price'], color = 'red', marker='+')
plt.plot(df['area'], reg.predict(df[['area']]), color = 'blue')


df1 = pd.read_csv('areas.csv')
df1 


p = reg.predict(df1)


df1['price'] = p 


df1.to_csv('prediction_price.csv', index = False)





df2 = pd.read_csv('canada_per_capita_income.csv')
df2.head() 


reg.fit(df2[['year']], df2['per capita income (US$)'])


df_pred = pd.DataFrame({'year' : [2020]})
reg.predict(df_pred)


reg.coef_, reg.intercept_


%matplotlib inline
plt.xlabel('per capita income (US$)', fontsize = 15)
plt.ylabel('year', fontsize = 15)
plt.scatter(df2['year'], df2['per capita income (US$)'], color = 'g', marker='.')
plt.plot(df2['year'], reg.predict(df2[['year']]), color = 'blue')





data = {
    'area': [2600, 3000, 3200, 3600, 4000],
    'bedrooms': [3, 4, np.nan, 3, 5],
    'age': [20, 15, 18, 30, 8],
    'price': [550000, 565000, 610000, 595000, 760000]
}

df3 = pd.DataFrame(data)
df3





import math
median_bedrooms = math.floor(df3['bedrooms'].median())
median_bedrooms


df3['bedrooms'] = df3['bedrooms'].fillna(median_bedrooms) 
df3


reg.fit(df3[['area', 'bedrooms', 'age']], df3['price'])


reg.coef_


reg.intercept_


df_pred = pd.DataFrame({
    'area' : [3000], 
    'bedrooms' : [3.0], 
    'age' : [40] 
})
reg.predict(df_pred)


df_pred = pd.DataFrame({
    'area' : [2500], 
    'bedrooms' : [4.0], 
    'age' : [5] 
})
reg.predict(df_pred)





from word2number import w2n
import math as m 


df4 = pd.read_csv('hiring.csv')
df4


df4['experience'] = df4['experience'].fillna('zero')
df4


df4['experience'] = df4['experience'].astype(str)
df4['experience'] = df4['experience'].apply(w2n.word_to_num)
df4 


test_score_median = m.floor(df4['test_score(out of 10)'].median())
test_score_median


df4['test_score(out of 10)'] = df4['test_score(out of 10)'].fillna(test_score_median)
df4 


reg.fit(df4[['experience', 'test_score(out of 10)', 'interview_score(out of 10)']], df4['salary($)']) 


reg.coef_


reg.intercept_


prediction_1 = pd.DataFrame({
    'experience' : [2], 
    'test_score(out of 10)' : [9.0], 
    'interview_score(out of 10)' : [6] 
})
reg.predict(prediction_1)


prediction_2 = pd.DataFrame({
    'experience' : [12], 
    'test_score(out of 10)' : [10.0], 
    'interview_score(out of 10)' : [10] 
})
reg.predict(prediction_2)








# Example Data 
x = [1, 2, 3]
y = [1, 2, 3]
m = len(x) 


# initialize the parameters / co-efficient
theta_0 = 0 # intercept
theta_1 = 0 # slop 


# Hyperparameters 
alpha = 0.01
num_of_iterations = 5


# Gradient Decent
for iteration in range(num_of_iterations):
    # compute gradients 
    sum_of_error_theta_0 = 0 
    sum_of_error_theta_1 = 0

    for i in range(m):
        hypothesis = theta_0 * theta_1 * x[i] # y = h(x) =  theta_0 * theta_1 * x
        print(f'Hypothesis Iteration {iteration}: Hypothesis = {hypothesis}')
        error = hypothesis - y[i]
        print(f'Error Iteration {iteration}: Error = {error}')
        sum_of_error_theta_0 = sum_of_error_theta_0 + error
        print(f'Sum of error theta 0 Iteration {iteration}: sum of error theta 0 = {sum_of_error_theta_0}')
        sum_of_error_theta_1 = sum_of_error_theta_1 + error * x[i]
        print(f'Sum of error theta 1 Iteration {iteration}: sum of error theta 1 = {sum_of_error_theta_1}')
        
    print()
     # update parameters  
    theta_0 = theta_0 - (alpha / m) * sum_of_error_theta_0
    theta_1 = theta_1 - (alpha / m) * sum_of_error_theta_1
    
    # print parameters / co-efficients 
    # if iteration % 5 == 0:
    print(f'Iteration {iteration}: theta 0 = {theta_0}, theta 1 = {theta_1}')


# final parameters / co-efficient 
print(f"Final parameters: theta_0 = {theta_0}, theta_1 = {theta_1}")



